
![image](https://github.com/user-attachments/assets/70bee99d-7703-449d-8d19-86893505e1cf)

<img src="https://github.com/user-attachments/assets/70bee99d-7703-449d-8d19-86893505e1cf" width="900" alt="RAG trainig">

# Why RAG?

LLMs are typically trained on vast datasets comprising text from books, Wikipedia, websites, and code from Github repositories. 
This training data is collected up to a specific date, meaning that an LLM’s knowledge has a cutoff point tied to when the training data was last updated. 
For instance, if an LLM’s training data only goes up to December 2023, it lacks information about anything that happened afterward.
